{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Multilingual Named Entity Recognition\n\n- Dataset: Subset of Cross-lingual TRansfer Evaluation of Multilingual Encoders (XTREME) benchmark, PAN-X, which is a dataset of Wikipedia articles in different languages in IOB2 format ","metadata":{}},{"cell_type":"code","source":"from datasets import get_dataset_config_names\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:03.780933Z","iopub.execute_input":"2022-12-27T17:22:03.781386Z","iopub.status.idle":"2022-12-27T17:22:04.609976Z","shell.execute_reply.started":"2022-12-27T17:22:03.781299Z","shell.execute_reply":"2022-12-27T17:22:04.608569Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"xtreme_subsets = get_dataset_config_names(\"xtreme\")\nlen(xtreme_subsets)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:04.612629Z","iopub.execute_input":"2022-12-27T17:22:04.613163Z","iopub.status.idle":"2022-12-27T17:22:05.372087Z","shell.execute_reply.started":"2022-12-27T17:22:04.613133Z","shell.execute_reply":"2022-12-27T17:22:05.371112Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"083653ead35b4cd4937856a6ee63e8ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/23.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c7abf4dcb77465b8f9ebf46d0464027"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"183"},"metadata":{}}]},{"cell_type":"markdown","source":"This dataset has a lot of different configurations. Let's look at the PAN-X datasets:","metadata":{}},{"cell_type":"code","source":"[s for s in xtreme_subsets if s.startswith(\"PAN\")][:10]","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:05.373635Z","iopub.execute_input":"2022-12-27T17:22:05.373991Z","iopub.status.idle":"2022-12-27T17:22:05.382647Z","shell.execute_reply.started":"2022-12-27T17:22:05.373959Z","shell.execute_reply":"2022-12-27T17:22:05.381478Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['PAN-X.af',\n 'PAN-X.ar',\n 'PAN-X.bg',\n 'PAN-X.bn',\n 'PAN-X.de',\n 'PAN-X.el',\n 'PAN-X.en',\n 'PAN-X.es',\n 'PAN-X.et',\n 'PAN-X.eu']"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict\nfrom collections import defaultdict","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:05.384496Z","iopub.execute_input":"2022-12-27T17:22:05.384788Z","iopub.status.idle":"2022-12-27T17:22:05.395364Z","shell.execute_reply.started":"2022-12-27T17:22:05.384763Z","shell.execute_reply":"2022-12-27T17:22:05.393662Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"langs = [\"de\", \"fr\", \"it\", \"en\"]\nfracs = [0.629, 0.229, 0.084, 0.059]\n\npanx = defaultdict(DatasetDict)\n\nfor lang, frac in zip(langs, fracs):\n    # load monolingual corpus\n    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n    # shuffle and downsample to spoken proportion\n    for split in ds:\n        panx[lang][split] = (ds[split]\n                             .shuffle(seed=0)\n                            .select(range(int(frac * ds[split].num_rows))))\n","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:05.398626Z","iopub.execute_input":"2022-12-27T17:22:05.398923Z","iopub.status.idle":"2022-12-27T17:22:37.369179Z","shell.execute_reply.started":"2022-12-27T17:22:05.398898Z","shell.execute_reply":"2022-12-27T17:22:37.368106Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.de (download: 223.17 MiB, generated: 9.08 MiB, post-processed: Unknown size, total: 232.25 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/234M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68472487e0454c2ebdf66f0f7442f7e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e86e40f0063d4d668a74804d03fd2c46"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.fr (download: 223.17 MiB, generated: 6.37 MiB, post-processed: Unknown size, total: 229.53 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04969ea0881f49eba17186f9d0a92a3f"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.it (download: 223.17 MiB, generated: 7.35 MiB, post-processed: Unknown size, total: 230.52 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa3f54c7c473446f9ea4220063488365"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.en (download: 223.17 MiB, generated: 7.30 MiB, post-processed: Unknown size, total: 230.47 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61170286c9704f47b1d32480d2900cfd"}},"metadata":{}}]},{"cell_type":"code","source":"counts = pd.DataFrame({lang: [panx[lang]['train'].num_rows] for lang in langs}, index=[\"Number of training examples\"])\ncounts/counts.sum(axis=1)[0]","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:37.370410Z","iopub.execute_input":"2022-12-27T17:22:37.371020Z","iopub.status.idle":"2022-12-27T17:22:37.392630Z","shell.execute_reply.started":"2022-12-27T17:22:37.370989Z","shell.execute_reply":"2022-12-27T17:22:37.391655Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                   de        fr        it        en\nNumber of training examples  0.628372  0.228771  0.083916  0.058941","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>de</th>\n      <th>fr</th>\n      <th>it</th>\n      <th>en</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Number of training examples</th>\n      <td>0.628372</td>\n      <td>0.228771</td>\n      <td>0.083916</td>\n      <td>0.058941</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"panx[\"de\"][\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:37.393761Z","iopub.execute_input":"2022-12-27T17:22:37.394045Z","iopub.status.idle":"2022-12-27T17:22:37.403528Z","shell.execute_reply.started":"2022-12-27T17:22:37.394022Z","shell.execute_reply":"2022-12-27T17:22:37.402689Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'tokens': ['2.000',\n  'Einwohnern',\n  'an',\n  'der',\n  'Danziger',\n  'Bucht',\n  'in',\n  'der',\n  'polnischen',\n  'Woiwodschaft',\n  'Pommern',\n  '.'],\n 'ner_tags': [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0],\n 'langs': ['de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de']}"},"metadata":{}}]},{"cell_type":"code","source":"panx[\"de\"][\"train\"].features","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:37.404915Z","iopub.execute_input":"2022-12-27T17:22:37.405691Z","iopub.status.idle":"2022-12-27T17:22:37.415150Z","shell.execute_reply.started":"2022-12-27T17:22:37.405661Z","shell.execute_reply":"2022-12-27T17:22:37.413815Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n 'ner_tags': Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None),\n 'langs': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"},"metadata":{}}]},{"cell_type":"markdown","source":"So the `ner_tags` are [IOB2 tags](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)).","metadata":{}},{"cell_type":"code","source":"tags = panx[\"de\"][\"train\"].features[\"ner_tags\"].feature\ntags","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:37.416893Z","iopub.execute_input":"2022-12-27T17:22:37.417235Z","iopub.status.idle":"2022-12-27T17:22:37.427072Z","shell.execute_reply.started":"2022-12-27T17:22:37.417204Z","shell.execute_reply":"2022-12-27T17:22:37.425979Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)"},"metadata":{}}]},{"cell_type":"code","source":"def create_tag_names(batch):\n    return {'ner_tags_str': [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:37.430419Z","iopub.execute_input":"2022-12-27T17:22:37.430749Z","iopub.status.idle":"2022-12-27T17:22:37.438937Z","shell.execute_reply.started":"2022-12-27T17:22:37.430724Z","shell.execute_reply":"2022-12-27T17:22:37.437601Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Creating a custom model for token classification\n\nNER can be viewed as token classification. Let's generate a custom model head for this purpose.","metadata":{}},{"cell_type":"code","source":"from typing import Optional\n\nimport torch\nimport torch.nn as nn\nfrom transformers import XLMRobertaConfig\nfrom transformers.configuration_utils import PretrainedConfig\nfrom transformers.modeling_outputs import TokenClassifierOutput\nfrom transformers.models.roberta.modeling_roberta import RobertaModel, RobertaPreTrainedModel\n\n\nclass XLMRobertaForTokenClassification(RobertaPreTrainedModel):  # inherits from model body. Knows how to load pretrained weights.\n    config_class = XLMRobertaConfig  # so that we use XLM-R config instead of Roberta\n\n    def __init__(self, config: PretrainedConfig):\n        super().__init__(config)\n        self.num_labels = config.num_labels\n        # Load model body\n        self.roberta = RobertaModel(config, add_pooling_layer=False)  # return all hidden states, not just the [CLS] ones\n        # Set up token classification head\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n        # Load and initialize weights\n        self.init_weights()\n\n    def forward(self, input_ids: Optional[torch.Tensor] = None, attention_mask: Optional[torch.Tensor] = None,\n                token_type_ids: Optional[torch.Tensor] = None, labels: Optional[torch.Tensor] = None, **kwargs):\n        # Use model body to get encoder representations\n        outputs = self.roberta(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, **kwargs)\n        # Apply classifier to encoder representations\n        sequence_output = self.dropout(outputs[0])\n        logits = self.classifier(sequence_output)\n        # Calculate losses\n        loss = None\n        if labels is not None:\n            loss_fct = nn.CrossEntropyLoss()\n            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n        # Return model output object\n        return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states,\n                                     attentions=outputs.attentions)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:37.440577Z","iopub.execute_input":"2022-12-27T17:22:37.440908Z","iopub.status.idle":"2022-12-27T17:22:40.512259Z","shell.execute_reply.started":"2022-12-27T17:22:37.440882Z","shell.execute_reply":"2022-12-27T17:22:40.510731Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"XLMRobertaForTokenClassification.__mro__","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:40.513931Z","iopub.execute_input":"2022-12-27T17:22:40.514225Z","iopub.status.idle":"2022-12-27T17:22:40.520881Z","shell.execute_reply.started":"2022-12-27T17:22:40.514199Z","shell.execute_reply":"2022-12-27T17:22:40.519700Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(__main__.XLMRobertaForTokenClassification,\n transformers.models.roberta.modeling_roberta.RobertaPreTrainedModel,\n transformers.modeling_utils.PreTrainedModel,\n torch.nn.modules.module.Module,\n transformers.modeling_utils.ModuleUtilsMixin,\n transformers.generation_utils.GenerationMixin,\n transformers.utils.hub.PushToHubMixin,\n object)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Loading a custom model","metadata":{}},{"cell_type":"code","source":"tags.names","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:40.522393Z","iopub.execute_input":"2022-12-27T17:22:40.522842Z","iopub.status.idle":"2022-12-27T17:22:40.539588Z","shell.execute_reply.started":"2022-12-27T17:22:40.522810Z","shell.execute_reply":"2022-12-27T17:22:40.538413Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"},"metadata":{}}]},{"cell_type":"code","source":"index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\ntag2index = {tag: idx for idx, tag in enumerate(tags.names)}","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:40.541123Z","iopub.execute_input":"2022-12-27T17:22:40.541706Z","iopub.status.idle":"2022-12-27T17:22:40.548457Z","shell.execute_reply.started":"2022-12-27T17:22:40.541669Z","shell.execute_reply":"2022-12-27T17:22:40.547706Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoConfig, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:23:18.483340Z","iopub.execute_input":"2022-12-27T17:23:18.483854Z","iopub.status.idle":"2022-12-27T17:23:18.523940Z","shell.execute_reply.started":"2022-12-27T17:23:18.483821Z","shell.execute_reply":"2022-12-27T17:23:18.522800Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"xlmr_model_name = \"xlm-roberta-base\"\n\n# Loading the config and overwriting parameters of the original pretrained model we want to change allows us to customize models\nxlmr_config = AutoConfig.from_pretrained(xlmr_model_name, \n                                         num_labels=tags.num_classes, id2label=index2tag, label2id=tag2index)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:40.564799Z","iopub.execute_input":"2022-12-27T17:22:40.565833Z","iopub.status.idle":"2022-12-27T17:22:40.800917Z","shell.execute_reply.started":"2022-12-27T17:22:40.565799Z","shell.execute_reply":"2022-12-27T17:22:40.799766Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c454e03ab5154d698457f4d078942e8f"}},"metadata":{}}]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:40.802366Z","iopub.execute_input":"2022-12-27T17:22:40.802779Z","iopub.status.idle":"2022-12-27T17:22:40.808337Z","shell.execute_reply.started":"2022-12-27T17:22:40.802744Z","shell.execute_reply":"2022-12-27T17:22:40.807242Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nxlmr_model = (XLMRobertaForTokenClassification\n              .from_pretrained(xlmr_model_name, config=xlmr_config)\n              .to(device))","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:22:40.809810Z","iopub.execute_input":"2022-12-27T17:22:40.810472Z","iopub.status.idle":"2022-12-27T17:23:02.202859Z","shell.execute_reply.started":"2022-12-27T17:22:40.810408Z","shell.execute_reply":"2022-12-27T17:23:02.202129Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4abe879376084a9ca45f943765f18795"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the tokenizer works\ntext = \"Jack Sparrow loves New York!\"\nxlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:28:24.663830Z","iopub.execute_input":"2022-12-27T17:28:24.664192Z","iopub.status.idle":"2022-12-27T17:28:26.125646Z","shell.execute_reply.started":"2022-12-27T17:28:24.664166Z","shell.execute_reply":"2022-12-27T17:28:26.124731Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def tag_text(text, tags, model, tokenizer):\n    # Get tokens with special characters\n    tokens = tokenizer(text).tokens()\n    # Encode the sequence into IDs\n    input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n    # Get predictions as distribution over 7 possible classes\n    outputs = model(input_ids).logits\n    # Take argmax to get most likely class per token\n    predictions = torch.argmax(outputs, dim=-1)\n    # Convert to DataFrame\n    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:30:37.601086Z","iopub.execute_input":"2022-12-27T17:30:37.601558Z","iopub.status.idle":"2022-12-27T17:30:37.609825Z","shell.execute_reply.started":"2022-12-27T17:30:37.601524Z","shell.execute_reply":"2022-12-27T17:30:37.608754Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"tag_text(text, tags, xlmr_model, xlmr_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T17:30:38.192781Z","iopub.execute_input":"2022-12-27T17:30:38.193122Z","iopub.status.idle":"2022-12-27T17:30:38.311322Z","shell.execute_reply.started":"2022-12-27T17:30:38.193096Z","shell.execute_reply":"2022-12-27T17:30:38.310132Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"            0      1      2    3      4  5     6      7  8      9\nTokens    <s>  ▁Jack  ▁Spar  row  ▁love  s  ▁New  ▁York  !   </s>\nTags    I-PER      O      O    O      O  O     O      O  O  I-PER","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jack</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁love</td>\n      <td>s</td>\n      <td>▁New</td>\n      <td>▁York</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>I-PER</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>O</td>\n      <td>I-PER</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
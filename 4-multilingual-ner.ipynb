{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Multilingual Named Entity Recognition\n\n- Dataset: Subset of Cross-lingual TRansfer Evaluation of Multilingual Encoders (XTREME) benchmark, PAN-X, which is a dataset of Wikipedia articles in different languages in IOB2 format ","metadata":{}},{"cell_type":"code","source":"from datasets import get_dataset_config_names\nimport pandas as pd\nfrom IPython.core.display import display\nimport numpy as np\n\nfull_context = pd.option_context('display.max_rows', 10, 'display.max_columns', 500)","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:14:27.003752Z","iopub.execute_input":"2022-12-28T14:14:27.004330Z","iopub.status.idle":"2022-12-28T14:14:27.716481Z","shell.execute_reply.started":"2022-12-28T14:14:27.004236Z","shell.execute_reply":"2022-12-28T14:14:27.715616Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"xtreme_subsets = get_dataset_config_names(\"xtreme\")\nlen(xtreme_subsets)","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:14:27.718379Z","iopub.execute_input":"2022-12-28T14:14:27.718817Z","iopub.status.idle":"2022-12-28T14:14:29.406659Z","shell.execute_reply.started":"2022-12-28T14:14:27.718795Z","shell.execute_reply":"2022-12-28T14:14:29.405750Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/9.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28b906e0cf254c56956106d723338e79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/23.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"581ea115dc40434697e3a1ad83d5deab"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"183"},"metadata":{}}]},{"cell_type":"markdown","source":"This dataset has a lot of different configurations. Let's look at the PAN-X datasets:","metadata":{}},{"cell_type":"code","source":"[s for s in xtreme_subsets if s.startswith(\"PAN\")][:10]","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:14:29.407884Z","iopub.execute_input":"2022-12-28T14:14:29.408128Z","iopub.status.idle":"2022-12-28T14:14:29.414534Z","shell.execute_reply.started":"2022-12-28T14:14:29.408105Z","shell.execute_reply":"2022-12-28T14:14:29.413505Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"['PAN-X.af',\n 'PAN-X.ar',\n 'PAN-X.bg',\n 'PAN-X.bn',\n 'PAN-X.de',\n 'PAN-X.el',\n 'PAN-X.en',\n 'PAN-X.es',\n 'PAN-X.et',\n 'PAN-X.eu']"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict\nfrom collections import defaultdict","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:14:29.416943Z","iopub.execute_input":"2022-12-28T14:14:29.417323Z","iopub.status.idle":"2022-12-28T14:14:29.433918Z","shell.execute_reply.started":"2022-12-28T14:14:29.417275Z","shell.execute_reply":"2022-12-28T14:14:29.433110Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"langs = [\"de\", \"fr\", \"it\", \"en\"]\nfracs = [0.629, 0.229, 0.084, 0.059]\n\npanx = defaultdict(DatasetDict)\n\nfor lang, frac in zip(langs, fracs):\n    # load monolingual corpus\n    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n    # shuffle and downsample to spoken proportion\n    for split in ds:\n        panx[lang][split] = (ds[split]\n                             .shuffle(seed=0)\n                            .select(range(int(frac * ds[split].num_rows))))\n","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:14:29.435023Z","iopub.execute_input":"2022-12-28T14:14:29.435436Z","iopub.status.idle":"2022-12-28T14:15:10.910446Z","shell.execute_reply.started":"2022-12-28T14:14:29.435411Z","shell.execute_reply":"2022-12-28T14:15:10.909621Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.de (download: 223.17 MiB, generated: 9.08 MiB, post-processed: Unknown size, total: 232.25 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/234M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5123dfa624b047e2bf2dce4cfaef0075"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.de/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"151b7e8e0d0e46ce83f16e3bf19857bf"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.fr (download: 223.17 MiB, generated: 6.37 MiB, post-processed: Unknown size, total: 229.53 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.fr/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3891caaa98c24dbeb3b23c3a64706b25"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.it (download: 223.17 MiB, generated: 7.35 MiB, post-processed: Unknown size, total: 230.52 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.it/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f46a9c1dff146c4a46ae16643c72e1e"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset xtreme/PAN-X.en (download: 223.17 MiB, generated: 7.30 MiB, post-processed: Unknown size, total: 230.47 MiB) to /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/20000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset xtreme downloaded and prepared to /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/349258adc25bb45e47de193222f95e68a44f7a7ab53c4283b3f007208a11bf7e. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"230b33c7687a44cc9b5e1f7bc2dba9da"}},"metadata":{}}]},{"cell_type":"code","source":"counts = pd.DataFrame({lang: [panx[lang]['train'].num_rows] for lang in langs}, index=[\"Number of training examples\"])\ncounts/counts.sum(axis=1)[0]","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:15:10.911563Z","iopub.execute_input":"2022-12-28T14:15:10.911810Z","iopub.status.idle":"2022-12-28T14:15:10.931096Z","shell.execute_reply.started":"2022-12-28T14:15:10.911787Z","shell.execute_reply":"2022-12-28T14:15:10.929923Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                   de        fr        it        en\nNumber of training examples  0.628372  0.228771  0.083916  0.058941","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>de</th>\n      <th>fr</th>\n      <th>it</th>\n      <th>en</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Number of training examples</th>\n      <td>0.628372</td>\n      <td>0.228771</td>\n      <td>0.083916</td>\n      <td>0.058941</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"panx[\"de\"][\"train\"][0]","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:15:10.932293Z","iopub.execute_input":"2022-12-28T14:15:10.932557Z","iopub.status.idle":"2022-12-28T14:15:10.939394Z","shell.execute_reply.started":"2022-12-28T14:15:10.932534Z","shell.execute_reply":"2022-12-28T14:15:10.938811Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'tokens': ['2.000',\n  'Einwohnern',\n  'an',\n  'der',\n  'Danziger',\n  'Bucht',\n  'in',\n  'der',\n  'polnischen',\n  'Woiwodschaft',\n  'Pommern',\n  '.'],\n 'ner_tags': [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0],\n 'langs': ['de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de']}"},"metadata":{}}]},{"cell_type":"code","source":"panx[\"de\"][\"train\"].features","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:15:10.940313Z","iopub.execute_input":"2022-12-28T14:15:10.940968Z","iopub.status.idle":"2022-12-28T14:15:10.949977Z","shell.execute_reply.started":"2022-12-28T14:15:10.940943Z","shell.execute_reply":"2022-12-28T14:15:10.949166Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n 'ner_tags': Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None),\n 'langs': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"},"metadata":{}}]},{"cell_type":"markdown","source":"So the `ner_tags` are [IOB2 tags](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)).","metadata":{}},{"cell_type":"code","source":"tags = panx[\"de\"][\"train\"].features[\"ner_tags\"].feature\ntags","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:15:10.951535Z","iopub.execute_input":"2022-12-28T14:15:10.951891Z","iopub.status.idle":"2022-12-28T14:15:10.960137Z","shell.execute_reply.started":"2022-12-28T14:15:10.951858Z","shell.execute_reply":"2022-12-28T14:15:10.959218Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)"},"metadata":{}}]},{"cell_type":"code","source":"from typing import Dict, List \n\ndef create_tag_names(batch: Dict[str, List]) -> Dict[str, List]:\n    return {'ner_tags_str': [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:15:10.963217Z","iopub.execute_input":"2022-12-28T14:15:10.963892Z","iopub.status.idle":"2022-12-28T14:15:10.969074Z","shell.execute_reply.started":"2022-12-28T14:15:10.963865Z","shell.execute_reply":"2022-12-28T14:15:10.968183Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Creating a custom model for token classification\n\nNER can be viewed as token classification. Let's generate a custom model head for this purpose.","metadata":{}},{"cell_type":"code","source":"from typing import Optional\n\nimport torch\nimport torch.nn as nn\nfrom transformers import XLMRobertaConfig\nfrom transformers.configuration_utils import PretrainedConfig\nfrom transformers.modeling_outputs import TokenClassifierOutput\nfrom transformers.models.roberta.modeling_roberta import RobertaModel, RobertaPreTrainedModel\n\n\nclass XLMRobertaForTokenClassification(RobertaPreTrainedModel):  # inherits from model body. Knows how to load pretrained weights.\n    config_class = XLMRobertaConfig  # so that we use XLM-R config instead of Roberta\n\n    def __init__(self, config: PretrainedConfig):\n        super().__init__(config)\n        self.num_labels = config.num_labels\n        # Load model body\n        self.roberta = RobertaModel(config, add_pooling_layer=False)  # return all hidden states, not just the [CLS] ones\n        # Set up token classification head\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n        # Load and initialize weights\n        self.init_weights()\n\n    def forward(self, input_ids: Optional[torch.Tensor] = None, attention_mask: Optional[torch.Tensor] = None,\n                token_type_ids: Optional[torch.Tensor] = None, labels: Optional[torch.Tensor] = None, **kwargs):\n        # Use model body to get encoder representations\n        outputs = self.roberta(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, **kwargs)\n        # Apply classifier to encoder representations\n        sequence_output = self.dropout(outputs[0])\n        logits = self.classifier(sequence_output)\n        # Calculate losses\n        loss = None\n        if labels is not None:            \n            loss_fct = nn.CrossEntropyLoss()\n            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n        # Return model output object\n        return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states,\n                                     attentions=outputs.attentions)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:15:10.970184Z","iopub.execute_input":"2022-12-28T14:15:10.970412Z","iopub.status.idle":"2022-12-28T14:15:13.583078Z","shell.execute_reply.started":"2022-12-28T14:15:10.970390Z","shell.execute_reply":"2022-12-28T14:15:13.582262Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"XLMRobertaForTokenClassification.__mro__","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:15:13.584844Z","iopub.execute_input":"2022-12-28T14:15:13.585528Z","iopub.status.idle":"2022-12-28T14:15:13.592753Z","shell.execute_reply.started":"2022-12-28T14:15:13.585461Z","shell.execute_reply":"2022-12-28T14:15:13.591827Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(__main__.XLMRobertaForTokenClassification,\n transformers.models.roberta.modeling_roberta.RobertaPreTrainedModel,\n transformers.modeling_utils.PreTrainedModel,\n torch.nn.modules.module.Module,\n transformers.modeling_utils.ModuleUtilsMixin,\n transformers.generation_utils.GenerationMixin,\n transformers.utils.hub.PushToHubMixin,\n object)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Loading a custom model","metadata":{}},{"cell_type":"code","source":"tags.names","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:15:13.594143Z","iopub.execute_input":"2022-12-28T14:15:13.594564Z","iopub.status.idle":"2022-12-28T14:15:13.604492Z","shell.execute_reply.started":"2022-12-28T14:15:13.594530Z","shell.execute_reply":"2022-12-28T14:15:13.603584Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"},"metadata":{}}]},{"cell_type":"code","source":"index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\ntag2index = {tag: idx for idx, tag in enumerate(tags.names)}","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:15:13.605874Z","iopub.execute_input":"2022-12-28T14:15:13.606713Z","iopub.status.idle":"2022-12-28T14:15:13.615075Z","shell.execute_reply.started":"2022-12-28T14:15:13.606677Z","shell.execute_reply":"2022-12-28T14:15:13.614301Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoConfig, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:15:13.616398Z","iopub.execute_input":"2022-12-28T14:15:13.617084Z","iopub.status.idle":"2022-12-28T14:15:13.632788Z","shell.execute_reply.started":"2022-12-28T14:15:13.617003Z","shell.execute_reply":"2022-12-28T14:15:13.631564Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"xlmr_model_name = \"xlm-roberta-base\"\n\n# Loading the config and overwriting parameters of the original pretrained model we want to change allows us to customize models\nxlmr_config = AutoConfig.from_pretrained(xlmr_model_name, \n                                         num_labels=tags.num_classes, id2label=index2tag, label2id=tag2index)","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:15:13.634179Z","iopub.execute_input":"2022-12-28T14:15:13.634457Z","iopub.status.idle":"2022-12-28T14:15:14.589590Z","shell.execute_reply.started":"2022-12-28T14:15:13.634425Z","shell.execute_reply":"2022-12-28T14:15:14.588668Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d3a9d7a00c04ae08d58aada10a30ebf"}},"metadata":{}}]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:15:14.590846Z","iopub.execute_input":"2022-12-28T14:15:14.591177Z","iopub.status.idle":"2022-12-28T14:15:14.595670Z","shell.execute_reply.started":"2022-12-28T14:15:14.591145Z","shell.execute_reply":"2022-12-28T14:15:14.594751Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nxlmr_model = (XLMRobertaForTokenClassification\n              .from_pretrained(xlmr_model_name, config=xlmr_config)\n              .to(device))","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:15:14.596676Z","iopub.execute_input":"2022-12-28T14:15:14.596985Z","iopub.status.idle":"2022-12-28T14:15:59.899999Z","shell.execute_reply.started":"2022-12-28T14:15:14.596954Z","shell.execute_reply":"2022-12-28T14:15:59.899374Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6d5e81e61924460a54a4d30e61e52f2"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForTokenClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias']\n- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'roberta.embeddings.position_ids', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test the tokenizer works\ntext = \"Jack Sparrow loves New York!\"\nxlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:15:59.901151Z","iopub.execute_input":"2022-12-28T14:15:59.901620Z","iopub.status.idle":"2022-12-28T14:16:07.417577Z","shell.execute_reply.started":"2022-12-28T14:15:59.901592Z","shell.execute_reply":"2022-12-28T14:16:07.416863Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1be1430f2f24ca1a66b72dbb0e804c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed90822027984757b3c41f75d489c6c7"}},"metadata":{}}]},{"cell_type":"code","source":"def tag_text(text, tags, model, tokenizer):\n    # Get tokens with special characters\n    tokens = tokenizer(text).tokens()\n    # Encode the sequence into IDs\n    input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n    # Get predictions as distribution over 7 possible classes\n    outputs = model(input_ids).logits\n    # Take argmax to get most likely class per token\n    predictions = torch.argmax(outputs, dim=-1)\n    # Convert to DataFrame\n    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:07.419043Z","iopub.execute_input":"2022-12-28T14:16:07.419669Z","iopub.status.idle":"2022-12-28T14:16:07.426028Z","shell.execute_reply.started":"2022-12-28T14:16:07.419634Z","shell.execute_reply":"2022-12-28T14:16:07.425435Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"tag_text(text, tags, xlmr_model, xlmr_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:07.427033Z","iopub.execute_input":"2022-12-28T14:16:07.427880Z","iopub.status.idle":"2022-12-28T14:16:07.631884Z","shell.execute_reply.started":"2022-12-28T14:16:07.427849Z","shell.execute_reply":"2022-12-28T14:16:07.631013Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"            0      1      2      3      4      5      6      7      8      9\nTokens    <s>  ▁Jack  ▁Spar    row  ▁love      s   ▁New  ▁York      !   </s>\nTags    I-PER  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG  I-PER","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jack</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁love</td>\n      <td>s</td>\n      <td>▁New</td>\n      <td>▁York</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>Tags</th>\n      <td>I-PER</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-ORG</td>\n      <td>I-PER</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"ignore_index_value_in_loss = -100\n\ndef tokenize_and_align_labels(examples: Dict[str, List]) -> Dict[str, List]:\n    \"\"\"Create word-level labels to subword tokens\"\"\"\n    \n    # XLM tokenize a sentence into subwords, where the sentence is split into words\n    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n    labels = []\n    for idx, label in enumerate(examples[\"ner_tags\"]):\n        # assign a subword a word-level integer index, and None to special tokens like <s>, </s>\n        word_ids = tokenized_inputs.word_ids(batch_index=idx)  \n        \n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None or word_idx == previous_word_idx:\n                # We are following the convention that only the first subword token be associated with a classification\n                # otherwise we will more heavily weight words that are broken up into multiple subtokens. Thus, when\n                # word_idx == previous_word_idx, we will use a special label to tell the loss function to ignore this index\n                # via the ignore_index flag for nn.CrossEntropyLoss\n                label_ids.append(ignore_index_value_in_loss)\n            else:\n                label_ids.append(label[word_idx])\n                previous_word_idx = word_idx\n        labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs\n","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:07.633060Z","iopub.execute_input":"2022-12-28T14:16:07.633347Z","iopub.status.idle":"2022-12-28T14:16:07.642075Z","shell.execute_reply.started":"2022-12-28T14:16:07.633317Z","shell.execute_reply":"2022-12-28T14:16:07.641151Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"example = panx[\"de\"][\"train\"][:3]\npd.DataFrame([example['tokens'][0]], index=['tokens'])","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:07.643508Z","iopub.execute_input":"2022-12-28T14:16:07.644130Z","iopub.status.idle":"2022-12-28T14:16:07.664781Z","shell.execute_reply.started":"2022-12-28T14:16:07.644098Z","shell.execute_reply":"2022-12-28T14:16:07.663954Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"           0           1   2    3         4      5   6    7           8   \\\ntokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \n\n                  9        10 11  \ntokens  Woiwodschaft  Pommern  .  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tokens</th>\n      <td>2.000</td>\n      <td>Einwohnern</td>\n      <td>an</td>\n      <td>der</td>\n      <td>Danziger</td>\n      <td>Bucht</td>\n      <td>in</td>\n      <td>der</td>\n      <td>polnischen</td>\n      <td>Woiwodschaft</td>\n      <td>Pommern</td>\n      <td>.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenized_input = xlmr_tokenizer(example['tokens'][0], truncation=True, is_split_into_words=True)\ntokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\nexample_labelled = tokenize_and_align_labels(panx[\"de\"][\"train\"][:3])\n\nwith full_context:\n    display(pd.DataFrame([tokens, example_labelled['labels'][0]], index=['tokens', 'labels']))","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:07.666028Z","iopub.execute_input":"2022-12-28T14:16:07.666537Z","iopub.status.idle":"2022-12-28T14:16:07.694341Z","shell.execute_reply.started":"2022-12-28T14:16:07.666504Z","shell.execute_reply":"2022-12-28T14:16:07.693448Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"          0       1           2     3    4     5     6     7     8      9   \\\ntokens   <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der  ▁Dan    zi   ger  ▁Buch   \nlabels  -100       0           0  -100    0     0     5  -100  -100      6   \n\n          10   11    12      13     14   15    16    17      18   19    20  \\\ntokens     t  ▁in  ▁der  ▁polni  schen  ▁Wo     i   wod  schaft  ▁Po  mmer   \nlabels  -100    0     0       5   -100    5  -100  -100    -100    6  -100   \n\n          21 22    23    24  \ntokens     n  ▁     .  </s>  \nlabels  -100  0  -100  -100  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>tokens</th>\n      <td>&lt;s&gt;</td>\n      <td>▁2.000</td>\n      <td>▁Einwohner</td>\n      <td>n</td>\n      <td>▁an</td>\n      <td>▁der</td>\n      <td>▁Dan</td>\n      <td>zi</td>\n      <td>ger</td>\n      <td>▁Buch</td>\n      <td>t</td>\n      <td>▁in</td>\n      <td>▁der</td>\n      <td>▁polni</td>\n      <td>schen</td>\n      <td>▁Wo</td>\n      <td>i</td>\n      <td>wod</td>\n      <td>schaft</td>\n      <td>▁Po</td>\n      <td>mmer</td>\n      <td>n</td>\n      <td>▁</td>\n      <td>.</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>labels</th>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>6</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>-100</td>\n      <td>5</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>6</td>\n      <td>-100</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>-100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def encode_panx_dataset(corpus):\n    return corpus.map(tokenize_and_align_labels, batched=True, remove_columns=['langs', 'ner_tags', 'tokens'])","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:07.695499Z","iopub.execute_input":"2022-12-28T14:16:07.695809Z","iopub.status.idle":"2022-12-28T14:16:07.701379Z","shell.execute_reply.started":"2022-12-28T14:16:07.695779Z","shell.execute_reply":"2022-12-28T14:16:07.700394Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"panx_de_encoded = encode_panx_dataset(panx[\"de\"])","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:07.702882Z","iopub.execute_input":"2022-12-28T14:16:07.703406Z","iopub.status.idle":"2022-12-28T14:16:09.927215Z","shell.execute_reply.started":"2022-12-28T14:16:07.703370Z","shell.execute_reply":"2022-12-28T14:16:09.926634Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/13 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ad9aea37e2f44efba87947adc4885a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f73b3e282bc42b0bdfc4fa455add2b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb53434b1178476bb6bf8c437ef9158e"}},"metadata":{}}]},{"cell_type":"code","source":"panx_de_encoded","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:09.928314Z","iopub.execute_input":"2022-12-28T14:16:09.929151Z","iopub.status.idle":"2022-12-28T14:16:09.935200Z","shell.execute_reply.started":"2022-12-28T14:16:09.929117Z","shell.execute_reply":"2022-12-28T14:16:09.934636Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 12580\n    })\n    validation: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 6290\n    })\n    test: Dataset({\n        features: ['input_ids', 'attention_mask', 'labels'],\n        num_rows: 6290\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Performance measures\n\nIn NER, *all* words of an entity must be predicted correctly in order for a prediction to be counted as correct. The library `seqeval` is designed for these kinds of tasks.","metadata":{}},{"cell_type":"code","source":"!pip install seqeval","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:09.939176Z","iopub.execute_input":"2022-12-28T14:16:09.939788Z","iopub.status.idle":"2022-12-28T14:16:26.085206Z","shell.execute_reply.started":"2022-12-28T14:16:09.939764Z","shell.execute_reply":"2022-12-28T14:16:26.083846Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m367.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval) (1.21.6)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval) (1.0.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=df9ef909a1d4721acd5ec4f2bf67e329606e500fe63f48f6469c10e6000adb10\n  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"def align_predictions(predictions, label_ids):\n    \"\"\"Prepare model outputs for metric evaluation by seqeval\"\"\"\n    preds = np.argmax(predictions, axis=2)\n    batch_size, seq_len = preds.shape\n    labels_list, preds_list = [], []\n    \n    for batch_idx in range(batch_size):\n        example_labels, example_preds = [], []\n        for seq_idx in range(seq_len):\n            # Ignore label IDs ignore_index_value_in_loss\n            if label_ids[batch_idx, seq_idx] != ignore_index_value_in_loss:\n                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n        \n        labels_list.append(example_labels)\n        preds_list.append(example_preds)\n    return preds_list, labels_list","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:26.087830Z","iopub.execute_input":"2022-12-28T14:16:26.088284Z","iopub.status.idle":"2022-12-28T14:16:26.099790Z","shell.execute_reply.started":"2022-12-28T14:16:26.088235Z","shell.execute_reply":"2022-12-28T14:16:26.098438Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Fine-tuning XLM-Roberta\n\nStrategy:\n- Fine-tune on the German (largest) subset of PAN-X\n- Evaluate zero-shot cross-lingual performance on French, Italian, and English","metadata":{}},{"cell_type":"code","source":"from transformers import TrainingArguments","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:26.101682Z","iopub.execute_input":"2022-12-28T14:16:26.102133Z","iopub.status.idle":"2022-12-28T14:16:30.228104Z","shell.execute_reply.started":"2022-12-28T14:16:26.102089Z","shell.execute_reply":"2022-12-28T14:16:30.227219Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"num_epochs = 3\nbatch_size=24\nlogging_steps = len(panx_de_encoded[\"train\"]) // batch_size\nmodel_name = f'{xlmr_model_name}-finetuned-panx-de'\ntraining_args = TrainingArguments(\n    output_dir=f'/kaggle/working/{model_name}', log_level=\"error\", num_train_epochs=num_epochs, \n    per_device_eval_batch_size=batch_size, per_gpu_train_batch_size=batch_size, evaluation_strategy=\"epoch\",\n    save_steps=1e6, weight_decay=0.01, disable_tqdm=False, logging_steps=logging_steps, push_to_hub=False\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:30.229119Z","iopub.execute_input":"2022-12-28T14:16:30.229349Z","iopub.status.idle":"2022-12-28T14:16:30.241252Z","shell.execute_reply.started":"2022-12-28T14:16:30.229326Z","shell.execute_reply":"2022-12-28T14:16:30.240442Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from seqeval.metrics import f1_score\n\ndef compute_metrics(eval_pred):\n    y_pred, y_true = align_predictions(eval_pred.predictions, eval_pred.label_ids)\n    return {\"f1\": f1_score(y_true, y_pred)}","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:30.242273Z","iopub.execute_input":"2022-12-28T14:16:30.242878Z","iopub.status.idle":"2022-12-28T14:16:30.643403Z","shell.execute_reply.started":"2022-12-28T14:16:30.242845Z","shell.execute_reply":"2022-12-28T14:16:30.641914Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"Define a *data collator* to pad each input sequence to the largest sequence length in a batch.","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:30.644776Z","iopub.execute_input":"2022-12-28T14:16:30.645097Z","iopub.status.idle":"2022-12-28T14:16:30.733791Z","shell.execute_reply.started":"2022-12-28T14:16:30.645068Z","shell.execute_reply":"2022-12-28T14:16:30.732906Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:30.735074Z","iopub.execute_input":"2022-12-28T14:16:30.735365Z","iopub.status.idle":"2022-12-28T14:16:30.740233Z","shell.execute_reply.started":"2022-12-28T14:16:30.735341Z","shell.execute_reply":"2022-12-28T14:16:30.739255Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Definte a `model_init` function so that we can avoid initializing a new model for every `Trainer` ","metadata":{}},{"cell_type":"code","source":"def model_init():\n    return (XLMRobertaForTokenClassification\n            .from_pretrained(xlmr_model_name, config=xlmr_config)\n            .to(device))","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:30.741427Z","iopub.execute_input":"2022-12-28T14:16:30.741745Z","iopub.status.idle":"2022-12-28T14:16:30.749492Z","shell.execute_reply.started":"2022-12-28T14:16:30.741718Z","shell.execute_reply":"2022-12-28T14:16:30.748612Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"Define trainer","metadata":{}},{"cell_type":"code","source":"from transformers import Trainer","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:16:30.750601Z","iopub.execute_input":"2022-12-28T14:16:30.751113Z","iopub.status.idle":"2022-12-28T14:16:30.931893Z","shell.execute_reply.started":"2022-12-28T14:16:30.751083Z","shell.execute_reply":"2022-12-28T14:16:30.930436Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"str(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:17:12.760993Z","iopub.execute_input":"2022-12-28T14:17:12.761444Z","iopub.status.idle":"2022-12-28T14:17:12.770193Z","shell.execute_reply.started":"2022-12-28T14:17:12.761406Z","shell.execute_reply":"2022-12-28T14:17:12.768806Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"'cpu'"},"metadata":{}}]},{"cell_type":"code","source":"trained_path = f'/kaggle/working/{model_name}/trained'\n\nif str(device) != 'cpu':\n    trainer = Trainer(model_init=model_init, args=training_args, data_collator=data_collator, compute_metrics=compute_metrics,\n                      train_dataset=panx_de_encoded[\"train\"], \n                      eval_dataset=panx_de_encoded[\"validation\"],\n                      tokenizer=xlmr_tokenizer,\n                     )\n    trainer.train()\n    trainer.save_model(trained_path)\n    # Switch back to CPU when done","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:17:32.348613Z","iopub.execute_input":"2022-12-28T14:17:32.348953Z","iopub.status.idle":"2022-12-28T14:17:32.354141Z","shell.execute_reply.started":"2022-12-28T14:17:32.348928Z","shell.execute_reply":"2022-12-28T14:17:32.353435Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"model = XLMRobertaForTokenClassification.from_pretrained(trained_path).to(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-28T14:17:33.504978Z","iopub.execute_input":"2022-12-28T14:17:33.505593Z","iopub.status.idle":"2022-12-28T14:17:36.637767Z","shell.execute_reply.started":"2022-12-28T14:17:33.505561Z","shell.execute_reply":"2022-12-28T14:17:36.636764Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}